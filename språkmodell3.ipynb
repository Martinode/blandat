{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cea1452-7094-457d-9330-86e3f32c6098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1ad494-1734-4c7d-bc08-921cc7fad0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "hello world\n",
    "this is a tiny character-level language model\n",
    "hello there\n",
    "\"\"\".lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d13c272-71f4-4192-8c59-be873accbfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "\n",
    "# Mapping char -> int\n",
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for ch,i in stoi.items()}\n",
    "\n",
    "def encode(s):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(ids):\n",
    "    return ''.join([itos[i] for i in ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923a8faf-579c-408b-9042-09183a4cd530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '-', 'a', 'c', 'd', 'e', 'g', 'h', 'i', 'l', 'm', 'n', 'o', 'r', 's', 't', 'u', 'v', 'w', 'y']\n",
      "[8, 6, 10, 10, 13]\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(chars)\n",
    "print(encode(\"hello\"))\n",
    "print(decode(encode(\"hello\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1a98d4-39a1-4ddb-90a4-27a9292dbc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "block_size = 16   # hur lång kontext modellen får se\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "def get_batch(batch_size=32):\n",
    "    ix = torch.randint(len(data) - block_size - 1, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f104e17d-69cd-4a84-a73e-06d0a6fb402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "        self.query = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim, bias=False)\n",
    "        self.register_buffer(\"mask\", torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        \n",
    "        K = self.key(x)     # (B, T, C)\n",
    "        Q = self.query(x)   # (B, T, C)\n",
    "        V = self.value(x)   # (B, T, C)\n",
    "\n",
    "        # Attention weights\n",
    "        att = Q @ K.transpose(-2, -1) / (C**0.5)   # (B, T, T)\n",
    "        att = att.masked_fill(self.mask[:T,:T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1)\n",
    "\n",
    "        out = att @ V  # (B, T, C)\n",
    "        return out\n",
    "\n",
    "class TinyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.pos_embed = nn.Embedding(block_size, embed_dim)\n",
    "\n",
    "        self.attn = SelfAttention(embed_dim)\n",
    "        self.ln1 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim*4, embed_dim)\n",
    "        )\n",
    "        \n",
    "        self.ln2 = nn.LayerNorm(embed_dim)\n",
    "        self.head = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "        token_emb = self.embed(idx)\n",
    "        pos_emb = self.pos_embed(torch.arange(T))\n",
    "        x = token_emb + pos_emb\n",
    "\n",
    "        # Block\n",
    "        x = x + self.attn(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "\n",
    "        logits = self.head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits\n",
    "        \n",
    "        # compute cross entropy loss\n",
    "        B, T, C = logits.shape\n",
    "        logits = logits.view(B*T, C)\n",
    "        targets = targets.view(B*T)\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "model = TinyTransformer(vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d13e76ba-d5d8-4227-a5a7-8a597894ca64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 3.4652\n",
      "step 200, loss 0.1098\n",
      "step 400, loss 0.0961\n",
      "step 600, loss 0.0933\n",
      "step 800, loss 0.0541\n",
      "step 1000, loss 0.0862\n",
      "step 1200, loss 0.0692\n",
      "step 1400, loss 0.0775\n",
      "step 1600, loss 0.0987\n",
      "step 1800, loss 0.0762\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "for step in range(2000):\n",
    "    xb, yb = get_batch()\n",
    "    logits, loss = model(xb, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if step % 200 == 0:\n",
    "        print(f\"step {step}, loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d712d25-87c3-4a90-b5b5-a453d5e85c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haracter-level language model\n",
      "hello thereld\n",
      "this is a tiny character-level language model\n",
      "hello there\n"
     ]
    }
   ],
   "source": [
    "def generate(model, start_text=\"h\", max_new_tokens=100):\n",
    "    model.eval()\n",
    "    idx = torch.tensor([encode(start_text)], dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        logits = model(idx[:, -block_size:])\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return decode(idx[0].tolist())\n",
    "\n",
    "print(generate(model, \"h\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fddbd2-a60f-499a-b29a-0c0fa13c62a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n",
      "this is a tiny character-level language model\n",
      "hello therelis a tiny character-level language\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, \"hell\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f5ad5e4-0315-48bd-9d23-5c5fa26121bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is a tiny character-level language model\n",
      "hellllo theracter-level language model\n",
      "hello therelelo tha\n"
     ]
    }
   ],
   "source": [
    "print(generate(model, \"this\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c047aee-a91c-41b7-95a5-50014117a616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
