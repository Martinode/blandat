{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "addea21e-536b-40cb-8872-c0f246f33f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vokabulär: ['\\n', ' ', 'a', 'e', 'g', 'h', 'i', 'j', 'k', 'm', 'n', 'r', 's', 't']\n",
      "vocab_size: 14\n",
      "Ex encode: [5, 3, 7]\n",
      "Ex decode: hej\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import random\n",
    "\n",
    "# 1. Liten leksakskorpus\n",
    "text = \"\"\"\n",
    "hej jag heter martin\n",
    "hej jag heter kerstin\n",
    "hej hej hej\n",
    "\"\"\"\n",
    "\n",
    "# 2. Bygg vokabulär av alla tecken som förekommer\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(\"Vokabulär:\", chars)\n",
    "print(\"vocab_size:\", vocab_size)\n",
    "\n",
    "# 3. Mappning char <-> int\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for ch, i in stoi.items()}\n",
    "\n",
    "def encode(s: str):\n",
    "    return [stoi[c] for c in s]\n",
    "\n",
    "def decode(ids):\n",
    "    return \"\".join(itos[i] for i in ids)\n",
    "\n",
    "print(\"Ex encode:\", encode(\"hej\"))\n",
    "print(\"Ex decode:\", decode(encode(\"hej\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cffa738-424a-4426-b874-e7c394babed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sekvenslängd: 56\n",
      "data: tensor([ 0,  5,  3,  7,  1,  7,  2,  4,  1,  5,  3, 13,  3, 11,  1,  9,  2, 11,\n",
      "        13,  6, 10,  0,  5,  3,  7,  1,  7,  2,  4,  1,  5,  3, 13,  3, 11,  1,\n",
      "         8,  3, 11, 12, 13,  6, 10,  0,  5,  3,  7,  1,  5,  3,  7,  1,  5,  3,\n",
      "         7,  0])\n",
      "xb shape: torch.Size([2, 16])\n",
      "yb shape: torch.Size([2, 16])\n",
      "xb[0]: tensor([ 3, 11,  1,  9,  2, 11, 13,  6, 10,  0,  5,  3,  7,  1,  7,  2])\n",
      "yb[0]: tensor([11,  1,  9,  2, 11, 13,  6, 10,  0,  5,  3,  7,  1,  7,  2,  4])\n",
      "xb[0] decoded: er martin\n",
      "hej ja\n",
      "yb[0] decoded: r martin\n",
      "hej jag\n"
     ]
    }
   ],
   "source": [
    "# Gör hela texten till en lång sekvens av index\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "# Vi delar upp i (input, target)-sekvenser med fast längd\n",
    "block_size = 16  # maxlängd på en sekvens modellen ser\n",
    "print(\"Total sekvenslängd:\", len(data))\n",
    "\n",
    "def get_batch(batch_size=4):\n",
    "    # Välj startpositioner slumpmässigt\n",
    "    ix = torch.randint(0, len(data) - block_size - 1, (batch_size,))\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    for i in ix:\n",
    "        x = data[i:i+block_size]       # input\n",
    "        y = data[i+1:i+block_size+1]   # target (1 steg fram)\n",
    "        x_batch.append(x)\n",
    "        y_batch.append(y)\n",
    "    x_batch = torch.stack(x_batch)  # (B, T)\n",
    "    y_batch = torch.stack(y_batch)  # (B, T)\n",
    "    return x_batch, y_batch\n",
    "\n",
    "xb, yb = get_batch(batch_size=2)\n",
    "print(\"data:\", data)\n",
    "print(\"xb shape:\", xb.shape)\n",
    "print(\"yb shape:\", yb.shape)\n",
    "print(\"xb[0]:\", xb[0])\n",
    "print(\"yb[0]:\", yb[0])\n",
    "print(\"xb[0] decoded:\", decode(xb[0].tolist()))\n",
    "print(\"yb[0] decoded:\", decode(yb[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfbb787-4ad5-45d3-b5bb-6d195c30eb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        assert d_model % num_heads == 0\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        # Gemensamma linjära lager som projicerar till Q, K, V\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "\n",
    "        # Ut-projektion\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, d_model)\n",
    "        B, T, D = x.shape\n",
    "\n",
    "        # 1) Linjära projektioner\n",
    "        Q = self.W_q(x)  # (B, T, D)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "\n",
    "        # 2) Dela upp i heads: (B, T, num_heads, d_k) -> (B, num_heads, T, d_k)\n",
    "        Q = Q.view(B, T, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(B, T, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(B, T, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # 3) Scaled dot-product attention per head:\n",
    "        #    scores = Q K^T / sqrt(d_k)\n",
    "        # Q: (B, H, T, d_k)\n",
    "        # K: (B, H, T, d_k) -> (B, H, d_k, T)\n",
    "        scores = Q @ K.transpose(-2, -1) / math.sqrt(self.d_k)  # (B, H, T, T)\n",
    "\n",
    "        # 4) Causal mask: tillåt bara att titta bakåt eller på sig själv\n",
    "        mask = torch.tril(torch.ones(T, T, device=x.device))  # (T, T)\n",
    "        # mask=1 behåll, mask=0 blockera (sätt till -inf)\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "\n",
    "        # 5) Softmax över sista dimensionen (”över T” = över positionsaxel)\n",
    "        A = F.softmax(scores, dim=-1)  # (B, H, T, T)\n",
    "\n",
    "        # 6) Vägda summor av V\n",
    "        out = A @ V  # (B, H, T, d_k)\n",
    "\n",
    "        # 7) Tillbaka till (B, T, D)\n",
    "        out = out.transpose(1, 2).contiguous().view(B, T, D)\n",
    "\n",
    "        # 8) Slutlig linjär projektion\n",
    "        out = self.W_o(out)  # (B, T, D)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7001d24-e20b-44a2-bd68-365a1ea3a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff):\n",
    "        super().__init__()\n",
    "        self.attn = MultiHeadSelfAttention(d_model, num_heads)\n",
    "        self.ln1 = nn.LayerNorm(d_model)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model),\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, d_model)\n",
    "\n",
    "        # 1) Self-attention + residual + layernorm\n",
    "        attn_out = self.attn(x)           # (B, T, d_model)\n",
    "        x = x + attn_out                  # residual\n",
    "        x = self.ln1(x)                   # layer norm\n",
    "\n",
    "        # 2) FFN + residual + layernorm\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = x + ffn_out\n",
    "        x = self.ln2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d1446e0-4dfd-4542-9fd7-9a8ab5b36ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniTransformerLM(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=32, num_heads=2, d_ff=64, num_layers=1, block_size=16):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "\n",
    "        # Token-embedding\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        # Positional embedding (learned)\n",
    "        self.pos_emb = nn.Embedding(block_size, d_model)\n",
    "\n",
    "        # Stapla ett (eller flera) transformerblock\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(d_model, num_heads, d_ff)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Slutlig projektion till vokabulärens storlek\n",
    "        self.lm_head = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        # x: (B, T)\n",
    "        B, T = x.shape\n",
    "        assert T <= self.block_size\n",
    "\n",
    "        # 1) Token + positionsembedding\n",
    "        tok_emb = self.token_emb(x)                      # (B, T, d_model)\n",
    "        pos = torch.arange(T, device=x.device)           # (T,)\n",
    "        pos_emb = self.pos_emb(pos)[None, :, :]          # (1, T, d_model)\n",
    "        h = tok_emb + pos_emb                            # (B, T, d_model)\n",
    "\n",
    "        # 2) Kör genom transformerblocken\n",
    "        for block in self.blocks:\n",
    "            h = block(h)                                 # (B, T, d_model)\n",
    "\n",
    "        # 3) Projektion till logits\n",
    "        logits = self.lm_head(h)                         # (B, T, vocab_size)\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # Gör om till (B*T, vocab_size) respektive (B*T)\n",
    "            B, T, C = logits.shape\n",
    "            logits_2d = logits.view(B*T, C)\n",
    "            targets_1d = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits_2d, targets_1d)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def generate(self, idx, max_new_tokens=50):\n",
    "        # idx: (B, T) startsekvens\n",
    "        for _ in range(max_new_tokens):\n",
    "            # klipp till block_size\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "\n",
    "            logits, _ = self(idx_cond)\n",
    "            # ta sista tidsstegets logits\n",
    "            logits_last = logits[:, -1, :]  # (B, vocab_size)\n",
    "            probs = F.softmax(logits_last, dim=-1)\n",
    "            # sampel från fördelningen\n",
    "            next_token = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            # append\n",
    "            idx = torch.cat([idx, next_token], dim=1)\n",
    "        return idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25cc0357-48ba-4a88-9a50-e21d133d5fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Steg 0, loss 2.8101\n",
      "Steg 50, loss 1.5255\n",
      "Steg 100, loss 0.7185\n",
      "Steg 150, loss 0.3904\n",
      "Steg 200, loss 0.2344\n",
      "Steg 250, loss 0.1506\n",
      "Steg 300, loss 0.1360\n",
      "Steg 350, loss 0.1288\n",
      "Steg 400, loss 0.1081\n",
      "Steg 450, loss 0.1123\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "model = MiniTransformerLM(vocab_size, d_model=32, num_heads=2, d_ff=64, num_layers=1, block_size=block_size)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Enkel träningsloop\n",
    "for step in range(500):  # 500 steg räcker ofta för att se något på så liten data\n",
    "    model.train()\n",
    "    xb, yb = get_batch(batch_size=16)\n",
    "    xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 50 == 0:\n",
    "        print(f\"Steg {step}, loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f13f883d-5e1b-4efe-aee2-a2d2c90bcd73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jag heter kerstin\n",
      "hej hej hej jag heter kerstin\n",
      "hej he\n"
     ]
    }
   ],
   "source": [
    "# Enkel inferens\n",
    "model.eval()\n",
    "start = \"jag \"\n",
    "start_ids = torch.tensor([encode(start)], dtype=torch.long).to(device)\n",
    "generated = model.generate(start_ids, max_new_tokens=50)\n",
    "print(decode(generated[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32035a7f-4568-4abc-98a9-e2aadacda13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
